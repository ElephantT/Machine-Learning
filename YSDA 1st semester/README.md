1st semester of Machine Learning at Yandex School of Data Analysis:
1. seminar 1 - Libraries
   - NumPy, Matplotlib, Plotly, Seaborn
2. seminar 2 - Linear Models
   - Linear models
   - Feature Engineering
   - Models training, hyperparameter tuning
   - Validation of models, cross-validation
3. seminar 3 - SVM
   - Linaer SVM
   - Different kernels for SVM
   - Categorical features
4. seminar 4 - PyTorch and NN
   - PyTorch
   - MNIST binary and 10 classes classification
5. seminar 5 - kNN
   - kNN
   - Scaling
6. seminar 6 & 7 - Bayes
   - Bayesian approach for ML, theory
   - Bayesian models
   - KDE - Kernel Density Estimator
7. seminar 7 - included at 6th sem
8. seminar 8 - Dimensionality reduction methods and Multiclass classification
   - PCA, Kernel PCA
   - PCA for face images
   - t-SNE
   - One vs One, One vs Rest
9. seminar 9 - Metrics and Sampling
   - Confusion matrix (Recall, Precision, F1, accuracy and etc)
   - Balanced data and sampling (over, under, smote)
10. seminar 10 - Decision trees
   - for regression/classififcation, hyperparameters
   - oblivious decision trees
11. seminar 11 - Ensembles in Machine Learning
   - bagging, boosting, staking
   - bias-variance decomposition
   - extra-trees - got insane boost on one Kaggle competition with them
12. seminar 12 - Gradient boosting
   - CatBoost vs XGBoost
   - parallel training on CPU ang GPU
   - Visualization
   - Binarization
   - Feature importance
